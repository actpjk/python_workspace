{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw data를 pandas와 파이썬으로 조작해서 그래프 만들어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 시각화란?\n",
    "- 데이터 분석 결과를 쉽게 이해할 수 있도록 시각적으로 표현하고 전달되는 과정\n",
    "- 탐색적 데이터 분석, 데이터 처리, 데이터 예측 모든 경우, 결과를 알아보기 쉽게 하기 위해 데이터 시각화는 필수적임\n",
    "- 다양한 시각화 기법 중, 가장 최신의 흥미로운 데이터 시각화 과정을 진행해보기로 함\n",
    "  - https://app.flourish.studio\n",
    "  - https://public.flourish.studio/visualisation/2897018/\n",
    "\n",
    "### 지금까지 익힌 데이터 처리 기술을 기반으로 데이터 시각화를 위해, raw data를 포멧에 맞추어 변환하여 그래프를 만들어보기로 함\n",
    "<img src=\"https://www.fun-coding.org/00_Images/covid_graph_ex2.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 시각화를 위한 데이터 포멧 이해\n",
    "- 데이터 시각화를 위해, raw data를 변환해야 함\n",
    "- 지금까지 익힌 데이터 처리 기술을 사용해서, 데이터를 변환하기로 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필요 데이터\n",
    "  - 국가명, 국기, 날짜별 확진자 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.fun-coding.org/00_Images/covid_ex_data_format.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. raw data 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "      <th>Combined_Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45001.0</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-01 21:58:49</td>\n",
       "      <td>34.223334</td>\n",
       "      <td>-82.461707</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Abbeville, South Carolina, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22001.0</td>\n",
       "      <td>Acadia</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-01 21:58:49</td>\n",
       "      <td>30.295065</td>\n",
       "      <td>-92.414197</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Acadia, Louisiana, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51001.0</td>\n",
       "      <td>Accomack</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-01 21:58:49</td>\n",
       "      <td>37.767072</td>\n",
       "      <td>-75.632346</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Accomack, Virginia, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16001.0</td>\n",
       "      <td>Ada</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-01 21:58:49</td>\n",
       "      <td>43.452658</td>\n",
       "      <td>-116.241552</td>\n",
       "      <td>195</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ada, Idaho, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19001.0</td>\n",
       "      <td>Adair</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-01 21:58:49</td>\n",
       "      <td>41.330756</td>\n",
       "      <td>-94.471059</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Adair, Iowa, US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS     Admin2  Province_State Country_Region          Last_Update  \\\n",
       "0  45001.0  Abbeville  South Carolina             US  2020-04-01 21:58:49   \n",
       "1  22001.0     Acadia       Louisiana             US  2020-04-01 21:58:49   \n",
       "2  51001.0   Accomack        Virginia             US  2020-04-01 21:58:49   \n",
       "3  16001.0        Ada           Idaho             US  2020-04-01 21:58:49   \n",
       "4  19001.0      Adair            Iowa             US  2020-04-01 21:58:49   \n",
       "\n",
       "         Lat       Long_  Confirmed  Deaths  Recovered  Active  \\\n",
       "0  34.223334  -82.461707          4       0          0       0   \n",
       "1  30.295065  -92.414197         47       1          0       0   \n",
       "2  37.767072  -75.632346          7       0          0       0   \n",
       "3  43.452658 -116.241552        195       3          0       0   \n",
       "4  41.330756  -94.471059          1       0          0       0   \n",
       "\n",
       "                    Combined_Key  \n",
       "0  Abbeville, South Carolina, US  \n",
       "1          Acadia, Louisiana, US  \n",
       "2         Accomack, Virginia, US  \n",
       "3                 Ada, Idaho, US  \n",
       "4                Adair, Iowa, US  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "PATH = \"COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "doc = pd.read_csv(PATH + \"04-01-2020.csv\", encoding='utf-8-sig')\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hubei</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-03-01T10:13:19</td>\n",
       "      <td>66907</td>\n",
       "      <td>2761</td>\n",
       "      <td>31536</td>\n",
       "      <td>30.9756</td>\n",
       "      <td>112.2707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>2020-03-01T23:43:03</td>\n",
       "      <td>3736</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>128.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2020-03-01T23:23:02</td>\n",
       "      <td>1694</td>\n",
       "      <td>34</td>\n",
       "      <td>83</td>\n",
       "      <td>43.0000</td>\n",
       "      <td>12.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-03-01T14:13:18</td>\n",
       "      <td>1349</td>\n",
       "      <td>7</td>\n",
       "      <td>1016</td>\n",
       "      <td>23.3417</td>\n",
       "      <td>113.4244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Henan</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-03-01T14:13:18</td>\n",
       "      <td>1272</td>\n",
       "      <td>22</td>\n",
       "      <td>1198</td>\n",
       "      <td>33.8820</td>\n",
       "      <td>113.6140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region          Last Update  Confirmed  Deaths  \\\n",
       "0          Hubei  Mainland China  2020-03-01T10:13:19      66907    2761   \n",
       "1            NaN     South Korea  2020-03-01T23:43:03       3736      17   \n",
       "2            NaN           Italy  2020-03-01T23:23:02       1694      34   \n",
       "3      Guangdong  Mainland China  2020-03-01T14:13:18       1349       7   \n",
       "4          Henan  Mainland China  2020-03-01T14:13:18       1272      22   \n",
       "\n",
       "   Recovered  Latitude  Longitude  \n",
       "0      31536   30.9756   112.2707  \n",
       "1         30   36.0000   128.0000  \n",
       "2         83   43.0000    12.0000  \n",
       "3       1016   23.3417   113.4244  \n",
       "4       1198   33.8820   113.6140  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "PATH = \"COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "doc = pd.read_csv(PATH + \"03-01-2020.csv\", encoding='utf-8-sig')\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3월 중순 데이터까지는 컬럼명이 Province/State, Country/Region 이고, 이후에는 Province_State, Country_Region 이므로, try except 구문을 사용해서, 데이터 조작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State  Country_Region  Confirmed\n",
       "0          Anhui  Mainland China        1.0\n",
       "1        Beijing  Mainland China       14.0\n",
       "2      Chongqing  Mainland China        6.0\n",
       "3         Fujian  Mainland China        1.0\n",
       "4          Gansu  Mainland China        NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = pd.read_csv(PATH + \"01-22-2020.csv\", encoding='utf-8-sig')\n",
    "try:\n",
    "    doc = doc[['Province_State', 'Country_Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "except:\n",
    "    doc = doc[['Province/State', 'Country/Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    doc.columns = ['Province_State', 'Country_Region', 'Confirmed']\n",
    "    \n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 데이터프레임 데이터 변환하기\n",
    "1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "2. 특정 컬럼에 없는 데이터 삭제하기\n",
    "3. 특정 컬럼의 데이터 타입 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State  Country_Region  Confirmed\n",
       "0          Anhui  Mainland China          1\n",
       "1        Beijing  Mainland China         14\n",
       "2      Chongqing  Mainland China          6\n",
       "3         Fujian  Mainland China          1\n",
       "5      Guangdong  Mainland China         26"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = pd.read_csv(PATH + \"01-22-2020.csv\", encoding='utf-8-sig')\n",
    "try:\n",
    "    doc = doc[['Province_State', 'Country_Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "except:\n",
    "    doc = doc[['Province/State', 'Country/Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    doc.columns = ['Province_State', 'Country_Region', 'Confirmed']\n",
    "doc = doc.dropna(subset=['Confirmed'])     # 2. 특정 컬럼에 없는 데이터 삭제하기\n",
    "doc = doc.astype({'Confirmed': 'int64'})   # 3. 특정 컬럼의 데이터 타입 변경하기\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 국가 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Combined_Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Botswana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Botswana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Burundi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Burundi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sierra Leone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sierra Leone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  UID iso2 iso3  code3  FIPS Admin2 Province_State  \\\n",
       "0           0             0  NaN   BW  NaN    NaN   NaN    NaN            NaN   \n",
       "1           1             1  NaN   BI  NaN    NaN   NaN    NaN            NaN   \n",
       "2           2             2  NaN   SL  NaN    NaN   NaN    NaN            NaN   \n",
       "3           3             3  4.0   AF  AFG    4.0   NaN    NaN            NaN   \n",
       "4           4             4  8.0   AL  ALB    8.0   NaN    NaN            NaN   \n",
       "\n",
       "  Country_Region       Lat      Long_  Combined_Key  \n",
       "0       Botswana       NaN        NaN      Botswana  \n",
       "1        Burundi       NaN        NaN       Burundi  \n",
       "2   Sierra Leone       NaN        NaN  Sierra Leone  \n",
       "3    Afghanistan  33.93911  67.709953   Afghanistan  \n",
       "4        Albania  41.15330  20.168300       Albania  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_info = pd.read_csv(\"COVID-19-master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv\", encoding='utf-8-sig')\n",
    "country_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두 데이터프레임 합쳐보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3333 entries, 0 to 3332\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Province_State_x  3330 non-null   object \n",
      " 1   Country_Region    3333 non-null   object \n",
      " 2   Confirmed         3333 non-null   int64  \n",
      " 3   Unnamed: 0        3308 non-null   float64\n",
      " 4   Unnamed: 0.1      3308 non-null   float64\n",
      " 5   UID               3308 non-null   float64\n",
      " 6   iso2              3308 non-null   object \n",
      " 7   iso3              3308 non-null   object \n",
      " 8   code3             3308 non-null   float64\n",
      " 9   FIPS              3302 non-null   float64\n",
      " 10  Admin2            3246 non-null   object \n",
      " 11  Province_State_y  3305 non-null   object \n",
      " 12  Lat               3203 non-null   float64\n",
      " 13  Long_             3203 non-null   float64\n",
      " 14  Combined_Key      3308 non-null   object \n",
      "dtypes: float64(7), int64(1), object(7)\n",
      "memory usage: 416.6+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.merge(doc, country_info, how='left', on='Country_Region')\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 잘못 매칭된 국가 정보 확인하기\n",
    "  - iso2 컬럼이 매칭되지 않은 확진자수 국가 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Province_State_x      3\n",
       "Country_Region        0\n",
       "Confirmed             0\n",
       "Unnamed: 0           25\n",
       "Unnamed: 0.1         25\n",
       "UID                  25\n",
       "iso2                 25\n",
       "iso3                 25\n",
       "code3                25\n",
       "FIPS                 31\n",
       "Admin2               87\n",
       "Province_State_y     28\n",
       "Lat                 130\n",
       "Long_               130\n",
       "Combined_Key         25\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State_x</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State_y</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Combined_Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State_x  Country_Region  Confirmed  Unnamed: 0  Unnamed: 0.1  UID  \\\n",
       "0            Anhui  Mainland China          1         NaN           NaN  NaN   \n",
       "1          Beijing  Mainland China         14         NaN           NaN  NaN   \n",
       "2        Chongqing  Mainland China          6         NaN           NaN  NaN   \n",
       "3           Fujian  Mainland China          1         NaN           NaN  NaN   \n",
       "4        Guangdong  Mainland China         26         NaN           NaN  NaN   \n",
       "\n",
       "  iso2 iso3  code3  FIPS Admin2 Province_State_y  Lat  Long_ Combined_Key  \n",
       "0  NaN  NaN    NaN   NaN    NaN              NaN  NaN    NaN          NaN  \n",
       "1  NaN  NaN    NaN   NaN    NaN              NaN  NaN    NaN          NaN  \n",
       "2  NaN  NaN    NaN   NaN    NaN              NaN  NaN    NaN          NaN  \n",
       "3  NaN  NaN    NaN   NaN    NaN              NaN  NaN    NaN          NaN  \n",
       "4  NaN  NaN    NaN   NaN    NaN              NaN  NaN    NaN          NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_rows = test_df[test_df['iso2'].isnull()]\n",
    "nan_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컬럼값 변경하기\n",
    "- Country_Region 국가명이 다양한 경우가 많았음\n",
    "- 각 케이스를 일괄적으로 변경할 키값이 존재하지 않고, 키가 될 수 있는 컬럼도 다양하고, 각 파일마다 키가 될 수 있는 컬럼이 변경되어, 키값으로 매칭이 불가하였음\n",
    "- 이에 각 케이스를 직접 확인해서, 국가명을 일관되게 변경할 수 있도록 별도 json 파일 작성\n",
    "- json 파일 기반으로 국가명을 일관되게 변경하기로 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### json.load() 함수로 파일로된 json 데이터를 사전처럼 다룰 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Mainland China', 'Macau', 'South Korea', 'Aruba', ' Azerbaijan', 'Bahamas, The', 'Cape Verde', 'Cayman Islands', 'Channel Islands', 'Curacao', 'Czech Republic', 'East Timor', 'Faroe Islands', 'French Guiana', 'Gambia, The', 'Gibraltar', 'Greenland', 'Guadeloupe', 'Guam', 'Guernsey', 'Hong Kong', 'Hong Kong SAR', 'Iran (Islamic Republic of)', 'Ivory Coast', 'Jersey', 'Macao SAR', 'Martinique', 'Mayotte', 'North Ireland', 'Palestine', 'Puerto Rico', 'Republic of Ireland', 'Republic of Korea', 'Republic of Moldova', 'Republic of the Congo', 'Reunion', 'Russian Federation', 'Saint Barthelemy', 'Saint Martin', 'St. Martin', 'Taipei and environs', 'The Bahamas', 'The Gambia', 'UK', 'Vatican City', 'Viet Nam', 'occupied Palestinian territory', 'Taiwan*', 'Malawi', 'South Sudan', 'Western Sahara', 'Namibia'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    print (json_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply() 함수 사용법\n",
    "- apply() 함수를 사용해서, 특정 컬럼값 변경 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영어</th>\n",
       "      <th>수학</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David</th>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       영어   수학\n",
       "Dave   60  100\n",
       "David  70   50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    '영어': [60, 70],\n",
    "    '수학': [100, 50]\n",
    "}, index = ['Dave', 'David'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    print (type(df_data))    \n",
    "    print (df_data.index)\n",
    "    print (df_data.values)    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 참고로 행이 두개 인데, 3번 func가 호출되는 이유는 apply() 함수 자체가, 첫 번째 행에 대해서는 두번 호출하도록 구현되어 있기 때문임 (전체 행의 처리를 위한 최적화 기법 적용 가능 여부를 확인코자 이와 같이 구현됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index(['Dave', 'David'], dtype='object')\n",
      "[60 70]\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index(['Dave', 'David'], dtype='object')\n",
      "[100  50]\n"
     ]
    }
   ],
   "source": [
    "df_func = df.apply(func, axis=0) # 열로 데이터 인자를 받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index(['영어', '수학'], dtype='object')\n",
      "[ 60 100]\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index(['영어', '수학'], dtype='object')\n",
      "[70 50]\n"
     ]
    }
   ],
   "source": [
    "df_func = df.apply(func, axis=1) # 행으로 받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    '영어': [60, 70],\n",
    "    '수학': [100, 50]\n",
    "}, index = ['Dave', 'David'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    df_data['영어'] = 80\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_func = df.apply(func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply() 함수를 사용해서, 국가 컬럼값 변경하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사전 작업 (doc 변수로 데이터프레임 파일 만들기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc = pd.read_csv(PATH + \"01-22-2020.csv\", encoding='utf-8-sig')\n",
    "try:\n",
    "    doc = doc[['Province_State', 'Country_Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "except:\n",
    "    doc = doc[['Province/State', 'Country/Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    doc.columns = ['Province_State', 'Country_Region', 'Confirmed']\n",
    "doc = doc.dropna(subset=['Confirmed'])     # 2. 특정 컬럼에 없는 데이터 삭제하기\n",
    "doc = doc.astype({'Confirmed': 'int64'})   # 3. 특정 컬럼의 데이터 타입 변경하기\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 변경할 국가명을 가지고 있는 json 파일 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    print (json_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Country_Region 이라는 컬럼값을 확인해서, 국가명이 다르게 기재되어 있을 경우에만, 지정한 국가명으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(row):\n",
    "    if row['Country_Region'] in json_data:\n",
    "        row['Country_Region'] = json_data[row['Country_Region']]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = doc.apply(func, axis=1)\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고: 파일명으로 데이터 변환하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lstrip(): 앞에(왼쪽에)서 특정 데이터 삭제하기, rstrip(): 뒤에(오른쪽에)서 특정 데이터 삭제하기\n",
    "- replace(변경전데이터, 변경후데이터): 문자열에서 변경전데이터 를 변경후데이터 로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"01-22-2020.csv\"\n",
    "date_column = data.split(\".\")[0].lstrip('0').replace('-', '/')\n",
    "date_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"01-22-2020.csv\"\n",
    "data.split('.')[0].lstrip(\"0\").replace('-', '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.columns = ['Province_State', 'Country_Region', date_column]\n",
    "doc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 중복 데이터 합치기\n",
    "- groupby() : 그룹별로 데이터를 집계하는 함수\n",
    "  - 동일한 컬럼값으로 묶어서 통계 또는 평균등을 확인할 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    '성별': ['남', '남', '남'],\n",
    "    '이름': ['David', 'Dave', 'Dave'],\n",
    "    '수학': [100, 50, 80],\n",
    "    '국어': [80, 70, 50]    \n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('이름').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('이름').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 국가별 총 확진자수 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc = pd.read_csv(PATH + \"01-22-2020.csv\", encoding='utf-8-sig')\n",
    "try:\n",
    "    doc = doc[['Province_State', 'Country_Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "except:\n",
    "    doc = doc[['Province/State', 'Country/Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    doc.columns = ['Province_State', 'Country_Region', 'Confirmed']\n",
    "doc = doc.dropna(subset=['Confirmed'])     # 2. 특정 컬럼에 없는 데이터 삭제하기\n",
    "doc = doc.astype({'Confirmed': 'int64'})   # 3. 특정 컬럼의 데이터 타입 변경하기\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.groupby('Country_Region').sum()  # 4. Country_Region 컬럼값이 동일한 케이스를 그룹화해서, 각 그룹별 합계 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 데이터 전처리하기\n",
    "- 지금까지의 과정을 모두 한데 모아서, 함수로 만들기\n",
    "  1. csv 파일 읽기\n",
    "  2. 'Country_Region', 'Confirmed' 두 개의 컬럼만 가져오기\n",
    "  3. 'Confirmed' 에 데이터가 없는 행 삭제하기\n",
    "  4. 'Country_Region'의 국가명을 여러 파일에 일관되게 변경하기\n",
    "  5. 'Confirmed' 데이터 타입을 int64(정수) 로 변경\n",
    "  6. 'Country_Region' 를 기준으로 중복된 데이터를 합치기\n",
    "  7. 파일명을 기반으로 날짜 문자열 변환하고, 'Confirmed' 컬럼명 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "def country_name_convert(row):\n",
    "    if row['Country_Region'] in json_data:\n",
    "        return json_data[row['Country_Region']]\n",
    "    return row['Country_Region']\n",
    "\n",
    "def create_dateframe(filename):\n",
    "\n",
    "    doc = pd.read_csv(PATH + filename, encoding='utf-8-sig')  # 1. csv 파일 읽기\n",
    "    try:\n",
    "        doc = doc[['Country_Region', 'Confirmed']]  # 2. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    except:\n",
    "        doc = doc[['Country/Region', 'Confirmed']]  # 2. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "        doc.columns = ['Country_Region', 'Confirmed']\n",
    "    doc = doc.dropna(subset=['Confirmed'])     # 3. 특정 컬럼에 없는 데이터 삭제하기\n",
    "    doc['Country_Region'] = doc.apply(country_name_convert, axis=1)   # 4. 'Country_Region'의 국가명을 여러 파일에 일관되게 변경하기\n",
    "    doc = doc.astype({'Confirmed': 'int64'})   # 5. 특정 컬럼의 데이터 타입 변경하기\n",
    "    doc = doc.groupby('Country_Region').sum()  # 6. 특정 컬럼으로 중복된 데이터를 합치기\n",
    "\n",
    "    # 7. 파일명을 기반으로 날짜 문자열 변환하고, 'Confirmed' 컬럼명 변경하기\n",
    "    date_column = filename.split(\".\")[0].lstrip('0').replace('-', '/') \n",
    "    doc.columns = [date_column]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = create_dateframe(\"01-22-2020.csv\")\n",
    "doc2 = create_dateframe(\"04-01-2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터프레임 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pd.merge(doc1, doc2, how='outer', left_index=True, right_index=True)\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 없는 데이터는 0으로 값 대체하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = doc.fillna(0)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고: 특정 폴더 파일 리스트 확인하기\n",
    "- split() 함수를 사용해서 특정 확장자를 가진 파일 리스트만 추출 가능\n",
    "- 문자열변수.split('.') 은 ['파일명', '확장자'] 와 같은 리스트가 반환되므로, 문자열변수.split('.')[-1] 을 통해, 이 중에서 마지막 아이템을 선택하면 됨\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PATH = 'COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "file_list = os.listdir(PATH)\n",
    "csv_list = list()\n",
    "\n",
    "for file in file_list:\n",
    "    if file.split(\".\")[-1] == 'csv':\n",
    "        csv_list.append(file)\n",
    "\n",
    "print (csv_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고: 리스트 정렬\n",
    "- 리스트변수.sort() : 오름차순 정렬 (디폴트)\n",
    "- 리스트변수.sort(reverse=True) : 내림차순 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_list.sort()\n",
    "csv_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 여러 데이터 수집, 전처리해서, 하나의 데이터프레임 만들기\n",
    "- 지금까지의 과정을 모두 한데 모아서, 함수로 만들기\n",
    "  1. 필요한 파일 리스트만 추출하기\n",
    "  2. 파일 리스트 정렬하기\n",
    "  3. 데이터프레임 전처리하기 (별도 create_dateframe() 함수)\n",
    "  4. 데이터프레임 합치기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최종 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "def country_name_convert(row):\n",
    "    if row['Country_Region'] in json_data:\n",
    "        return json_data[row['Country_Region']]\n",
    "    return row['Country_Region']\n",
    "\n",
    "def create_dateframe(filename):\n",
    "\n",
    "    doc = pd.read_csv(PATH + filename, encoding='utf-8-sig')  # 1. csv 파일 읽기\n",
    "    try:\n",
    "        doc = doc[['Country_Region', 'Confirmed']]  # 2. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    except:\n",
    "        doc = doc[['Country/Region', 'Confirmed']]  # 2. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "        doc.columns = ['Country_Region', 'Confirmed']\n",
    "    doc = doc.dropna(subset=['Confirmed'])     # 3. 특정 컬럼에 없는 데이터 삭제하기\n",
    "    doc['Country_Region'] = doc.apply(country_name_convert, axis=1)   # 4. 'Country_Region'의 국가명을 여러 파일에 일관되게 변경하기\n",
    "    doc = doc.astype({'Confirmed': 'int64'})   # 5. 특정 컬럼의 데이터 타입 변경하기\n",
    "    doc = doc.groupby('Country_Region').sum()  # 6. 특정 컬럼으로 중복된 데이터를 합치기\n",
    "\n",
    "    # 7. 파일명을 기반으로 날짜 문자열 변환하고, 'Confirmed' 컬럼명 변경하기\n",
    "    date_column = filename.split(\".\")[0].lstrip('0').replace('-', '/') \n",
    "    doc.columns = [date_column]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_dateframe_by_path(PATH):\n",
    "\n",
    "    file_list, csv_list = os.listdir(PATH), list()\n",
    "    first_doc = True\n",
    "    for file in file_list:\n",
    "        if file.split(\".\")[-1] == 'csv':\n",
    "            csv_list.append(file)\n",
    "    csv_list.sort()\n",
    "    \n",
    "    for file in csv_list:\n",
    "        doc = create_dateframe(file)\n",
    "        if first_doc:\n",
    "            final_doc, first_doc = doc, False\n",
    "        else:\n",
    "            final_doc = pd.merge(final_doc, doc, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "    final_doc = final_doc.fillna(0)\n",
    "    return final_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "doc = generate_dateframe_by_path(PATH)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고: 데이터 타입 변환이 가능한 모든 열의 데이터 타입 변경\n",
    "- pd.astype(데이터타입)\n",
    "  - object 는 파이썬의 str 또는 혼용 데이터 타입 (문자열)\n",
    "  - int64 는 파이썬의 int (정수)\n",
    "  - float64 는 파이썬의 float (부동소숫점)\n",
    "  - bool 는 파이썬의 bool (True 또는 False 값을 가지는 boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = doc.astype('int64')\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pandas 라이브러리로 csv 파일 쓰기\n",
    "- pandas dataframe 데이터를 csv 파일로 저장하기 위해, to_csv() 함수 사용\n",
    "    ```\n",
    "    doc.to_csv(\"00_data/students_default.csv\")\n",
    "    ```\n",
    "\n",
    "- encoding 옵션 사용 가능\n",
    "    ```\n",
    "    doc.to_csv(\"00_data/students_default.csv\", encoding='utf-8-sig')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_csv(\"COVID-19-master/final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "386.319px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
